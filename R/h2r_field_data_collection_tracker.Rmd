---
title: 'ETH H2R: Data Collection Tracker'
author: "REACH"
date: "`r Sys.Date()`"
output: 
html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_file = paste0(dirname(inputFile), '/h2r_field_data_collection_tracker_', format(Sys.Date(), '%Y_%m_%d'),'.html')) })
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)

# read packages
library(tidyverse)
library(lubridate)
library(glue)
library(htmlwidgets)

df_tool_data <- readxl::read_excel("../inputs/ETH2002_H2R_data.xlsx")  |>  
  mutate(uuid = `_uuid`,
         start_date = as_date(start),
         start = as_datetime(start),
         end = as_datetime(end))

# days that contain data
df_days_for_data_collection <- df_tool_data |> 
  select(start_date) |> 
  unique() |> 
  arrange(start_date) |> 
  pull()

df_data_support_cl_log <- df_tool_data |> 
  select(uuid, loc_woreda, loc_kebele)

# cleaning log handling
df_cl_log <- read_csv(file = "../inputs/combined_checks_h2r_eth.csv") |> 
  left_join(df_data_support_cl_log, by = "uuid")

# change_response logs that affect stats in the data collection progress
cl_log_change_response <- df_cl_log |> 
  filter(type == "change_response", 
         !is.na(value),
         reviewed == 1, 
         adjust_log != "delete_log", 
  ) |> 
  select(uuid, name, value)

# updated tool data
df_updated_tool_data <- df_tool_data

# get uuids from cleaning log
uuids_chg_response <- cl_log_change_response |> pull(uuid) |> unique()

for (current_uuid in uuids_chg_response) {
  current_uuid_data <- cl_log_change_response |> 
    filter(uuid == current_uuid) |> 
    mutate(value = ifelse(name == "enumerator_id", as.numeric(value), value)) |> 
    pivot_wider(names_from = "name", values_from = "value", uuid)
  print(current_uuid_data)
  # process current updates
  df_current_updated <- df_updated_tool_data |> 
    rows_update(y = current_uuid_data, by = "uuid")
  # update the parent dataset with current updates
  df_updated_tool_data <- df_current_updated
}

# enumerator performance data
df_enum_performance <- df_updated_tool_data |> 
  mutate(int.survey_time_interval = lubridate::time_length(end - start, unit = "min"),
         int.survey_time_interval = ceiling(int.survey_time_interval))


df_samples_required <- readxl::read_excel("../support_files/20230306_prepared_location_data_h2r.xlsx", sheet = "settlement_list")

df_logical_check_description <-  readxl::read_excel("../support_files/V5_Logical checks template_ETH2002.xlsx") %>% 
  janitor::clean_names() %>% 
  select(check_number, check_description) %>% 
  mutate(check_number = as.character(check_number))

# tool
loc_tool <- "../inputs/ETH2002_H2R_tool.xlsx"

df_survey <- readxl::read_excel(loc_tool, sheet = "survey")
df_choices <- readxl::read_excel(loc_tool, sheet = "choices") |> 
  mutate(code = name, label = `label::english`)

df_zone_info <- df_choices |> 
  filter(list_name %in% c("zone_mv_list")) |> 
  select(code, zone = label)

df_woreda_info <- df_choices |> 
  filter(list_name %in% c("woreda_mv_list")) |> 
  select(code, woreda = label)

df_kebele_info <- df_choices |> 
  filter(list_name %in% c("kebele_mv_list")) |> 
  select(code, kebele = label)

df_zone_to_kebele_info <- df_choices |> 
  filter(list_name %in% c("kebele_mv_list")) |> 
  select(zone_code = zone, woreda_code = woreda, code, kebele = label) |> 
  left_join(df_zone_info, by = c("zone_code" = "code")) |>
  relocate(zone, .after = zone_code) |>
  left_join(df_woreda_info, by = c("woreda_code" = "code")) |>
  relocate(woreda, .after = woreda_code) |>
  select(-c(zone_code, woreda_code))

# functions for changing some options in the table

dt_options_fewcols <- function(x){
  DT::datatable(x,
                rownames = FALSE,
                options = list(
                  pageLength = 20,
                  initComplete = JS(
                    "function(settings, json) {",
                    "$(this.api().table().header()).css({'background-color': '#333', 'color': '#fff'});",
                    "}")
                )
  )
}

```

>There are **`r nrow(df_updated_tool_data)`** total number of surveys done as of **`r df_days_for_data_collection[length(df_days_for_data_collection)]`**.

### Summary on the surveys done

```{r, echo = FALSE}

df_samp_per_location <- df_samples_required |> 
  group_by(kebele) |> 
  summarise(required_samples = n())

df_cl_surveys_for_deletion <- df_cl_log |> 
  filter(type %in% "remove_survey", reviewed == 1, !adjust_log %in% "delete_log") |>
  group_by(loc_kebele) |> 
  distinct(uuid) |>
  summarise(surveys_for_deletion = n())

df_updated_tool_data |> 
  group_by(loc_kebele) |> 
  summarise(number_of_surveys = n()) |> 
  arrange(loc_kebele) |> 
  right_join(df_samp_per_location, by = c("loc_kebele" = "kebele")) |> 
  left_join(df_cl_surveys_for_deletion, by = "loc_kebele") |> 
  mutate(number_of_surveys = ifelse(is.na(number_of_surveys), 0, number_of_surveys),
         surveys_for_deletion = ifelse(is.na(surveys_for_deletion), 0, surveys_for_deletion),
         int.surveys_and_deletion = number_of_surveys - surveys_for_deletion,
         remaining_surveys = required_samples - int.surveys_and_deletion ) |> 
  select(-c(int.surveys_and_deletion)) |> 
  left_join(df_zone_to_kebele_info, by = c("loc_kebele" = "code")) |> 
  relocate(c(zone, woreda, loc_kebele, kebele), .before = number_of_surveys) |>
  dt_options_fewcols()

```

### Daily enumerator performance

The average survey time for all the data is: **`r round(mean(df_enum_performance$int.survey_time_interval), 0)`** Minutes

```{r, echo = FALSE}

df_enum_performance |> 
  group_by(loc_zone, loc_woreda, loc_kebele, start_date, enumerator_id) |> 
  summarise(number_of_interviews_done = n(), `average_survey_time(minutes)` = round(mean(int.survey_time_interval, na.rm = TRUE), 0)) |> 
  left_join(df_zone_info, by = c("loc_zone" = "code")) |> 
  relocate(zone, .after = loc_zone) |> 
  left_join(df_woreda_info, by = c("loc_woreda" = "code")) |> 
  relocate(woreda, .after = loc_woreda) |>
  left_join(df_kebele_info, by = c("loc_kebele" = "code")) |> 
  relocate(kebele, .after = loc_kebele) |>
  ungroup() |> 
  select(-c(loc_zone, loc_woreda, loc_kebele)) |> 
  dt_options_fewcols()
```

## Looking into the cleaning log

### Number of issues by issue_id

```{r, echo = FALSE}
df_cl_log |> 
  group_by(issue_id, issue) |> 
  summarise(number_of_issues_by_issue_id = n()) |>
  mutate(int.issue_id = str_extract(string = issue_id, pattern = "[0-9]{1,3}")) |> 
  left_join(df_logical_check_description, by = c("int.issue_id" = "check_number")) |> 
  mutate(issue = ifelse(str_detect(string = issue_id, pattern = "[0-9]{1,3}"), paste(check_description, "[", issue, "]"), issue)) |> 
  select(-c(int.issue_id, check_description))  |> 
  dt_options_fewcols()
```

### Number of issues by enumerator

```{r, echo = FALSE}
df_cl_log |> 
  group_by(enumerator_id) |> 
  summarise(number_of_issues_by_enumerator_id = n()) |>
  dt_options_fewcols()
```

### Number of issues by enumerator and issue_id

```{r, echo = FALSE}
df_cl_log |> 
  group_by(enumerator_id, issue_id, issue) |> 
  summarise(number_of_issues_by_enumerator_and_issue_id = n()) |>
  mutate(int.issue_id = str_extract(string = issue_id, pattern = "[0-9]{1,3}")) |> 
  left_join(df_logical_check_description, by = c("int.issue_id" = "check_number")) |> 
  mutate(issue = ifelse(str_detect(string = issue_id, pattern = "[0-9]{1,3}"), paste(check_description, "[", issue, "]"), issue)) |> 
  select(-c(int.issue_id, check_description))  |> 
  dt_options_fewcols()
```

### Enumerators with surveys for deletion

```{r, echo = FALSE}
df_cl_log |> 
  filter(type %in% c("remove_survey"), reviewed == 1, !adjust_log %in% c("delete_log")) |> 
  group_by(enumerator_id) |> 
  summarise(number_of_surveys_for_deletion_by_enumerator = n()) |>
  dt_options_fewcols()
```
